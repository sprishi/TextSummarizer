import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
from torch.utils.data import Dataset, DataLoader
import pmdarima as pm
from statsmodels.tsa.stattools import adfuller
import matplotlib.pyplot as plt
from tqdm import tqdm

class TD3CPredictionPipeline:
    def __init__(self, window_size=30, n_iterations=100):
        self.window_size = window_size
        self.n_iterations = n_iterations
        self.scaler = StandardScaler()
        self.lstm_model = None
        self.arima_model = None
        
    def preprocess_data(self, df):
        """Preprocess data with feature engineering"""
        df = df.copy()
        df['WS_Spot_next_day'] = df['WS_Spot'].shift(-1)
        
        # Lag features
        for col in ['WS_Spot', 'brent_price', 'laden_perc']:
            df[f'{col}_lag1'] = df[col].shift(1)
        
        # Rolling means
        for window in [7, 14]:
            df[f'WS_Spot_ma_{window}'] = df['WS_Spot'].rolling(window=window).mean()
        
        # Handle monthly features
        monthly_cols = ['Exp_TD3C_KBD', 'Count_VLCC']
        for col in monthly_cols:
            df[f'{col}_ma7'] = df[col].rolling(7).mean().fillna(method='ffill')
        
        df = df.dropna()
        return df
    
    def train_evaluate_models(self, df, train_end='2023-12-31', val_end='2024-06-30'):
        """Train and evaluate both LSTM and ARIMA models"""
        # Split data
        train_df = df[df['date'] <= train_end]
        val_df = df[(df['date'] > train_end) & (df['date'] <= val_end)]
        test_df = df[df['date'] > val_end]
        
        # Train and evaluate LSTM
        lstm_results = self._train_evaluate_lstm(train_df, val_df, test_df)
        
        # Train and evaluate ARIMA
        arima_results = self._train_evaluate_arima(train_df, val_df, test_df)
        
        return lstm_results, arima_results
    
    def _build_lstm_model(self, input_size):
        """Build LSTM model"""
        model = nn.Sequential(
            nn.LSTM(input_size, 64, num_layers=2, dropout=0.2, batch_first=True),
            nn.Linear(64, 1)
        )
        return model
    
    def _train_evaluate_lstm(self, train_df, val_df, test_df):
        """Train and evaluate LSTM model with sliding window"""
        # Scale features
        feature_cols = [col for col in train_df.columns if col not in ['date', 'WS_Spot_next_day']]
        X_train = self.scaler.fit_transform(train_df[feature_cols])
        X_val = self.scaler.transform(val_df[feature_cols])
        X_test = self.scaler.transform(test_df[feature_cols])
        
        # Build and train model
        self.lstm_model = self._build_lstm_model(len(feature_cols))
        
        # Train with sliding window
        train_predictions = []
        val_predictions = []
        test_predictions = []
        
        print("Training LSTM...")
        for i in tqdm(range(len(X_train) - self.window_size)):
            # Get window
            X_window = X_train[i:i+self.window_size]
            y_true = train_df['WS_Spot_next_day'].iloc[i+self.window_size]
            
            # Train on window
            self.lstm_model.train()
            optimizer = optim.Adam(self.lstm_model.parameters())
            criterion = nn.L1Loss()
            
            X_tensor = torch.FloatTensor(X_window).unsqueeze(0)
            y_tensor = torch.FloatTensor([y_true])
            
            optimizer.zero_grad()
            y_pred = self.lstm_model(X_tensor)
            loss = criterion(y_pred, y_tensor)
            loss.backward()
            optimizer.step()
            
            train_predictions.append(y_pred.item())
        
        # Validation predictions
        self.lstm_model.eval()
        with torch.no_grad():
            for i in range(len(X_val) - self.window_size):
                X_window = X_val[i:i+self.window_size]
                X_tensor = torch.FloatTensor(X_window).unsqueeze(0)
                y_pred = self.lstm_model(X_tensor)
                val_predictions.append(y_pred.item())
        
        # Test predictions with range
        test_results = []
        self.lstm_model.train()  # Enable dropout for MC dropout
        
        for i in range(len(X_test) - self.window_size):
            X_window = X_test[i:i+self.window_size]
            X_tensor = torch.FloatTensor(X_window).unsqueeze(0)
            
            # Monte Carlo predictions for range
            predictions = []
            for _ in range(self.n_iterations):
                with torch.no_grad():
                    pred = self.lstm_model(X_tensor).item()
                    predictions.append(pred)
            
            mean_pred = np.mean(predictions)
            lower_bound = np.percentile(predictions, 10)
            upper_bound = np.percentile(predictions, 90)
            direction = np.sign(mean_pred - X_test[i+self.window_size-1, 0])
            
            test_results.append({
                'Date': test_df.iloc[i+self.window_size]['date'],
                'Actual': test_df.iloc[i+self.window_size]['WS_Spot_next_day'],
                'Predicted': mean_pred,
                'Lower_Bound': lower_bound,
                'Upper_Bound': upper_bound,
                'Direction': direction
            })
        
        test_df = pd.DataFrame(test_results)
        
        return {
            'train_mae': mean_absolute_error(train_df['WS_Spot_next_day'][self.window_size:], train_predictions),
            'val_mae': mean_absolute_error(val_df['WS_Spot_next_day'][self.window_size:], val_predictions),
            'test_results': test_df
        }
    
    def _train_evaluate_arima(self, train_df, val_df, test_df):
        """Train and evaluate ARIMA model"""
        print("Training ARIMA...")
        self.arima_model = pm.auto_arima(train_df['WS_Spot'],
                                       start_p=1, start_q=1,
                                       max_p=3, max_q=3,
                                       m=1, seasonal=False,
                                       d=1, trace=True,
                                       error_action='ignore',
                                       suppress_warnings=True)
        
        # Make predictions
        train_predictions = self.arima_model.predict_in_sample()
        val_predictions = self.arima_model.predict(n_periods=len(val_df))
        
        # Test predictions with confidence intervals
        test_results = []
        for i in range(len(test_df)):
            pred, conf_int = self.arima_model.predict(n_periods=1, return_conf_int=True)
            test_results.append({
                'Date': test_df.iloc[i]['date'],
                'Actual': test_df.iloc[i]['WS_Spot_next_day'],
                'Predicted': pred[0],
                'Lower_Bound': conf_int[0][0],
                'Upper_Bound': conf_int[0][1],
                'Direction': np.sign(pred[0] - test_df.iloc[i-1]['WS_Spot'] if i > 0 else 0)
            })
            # Update model
            self.arima_model.update(test_df.iloc[i]['WS_Spot'])
        
        test_df = pd.DataFrame(test_results)
        
        return {
            'train_mae': mean_absolute_error(train_df['WS_Spot_next_day'], train_predictions),
            'val_mae': mean_absolute_error(val_df['WS_Spot_next_day'], val_predictions),
            'test_results': test_df
        }
    
    def predict_next_day(self, df, model_type='lstm'):
        """Predict next day using full dataset"""
        # Preprocess latest data
        latest_data = self.preprocess_data(df)
        
        if model_type.lower() == 'lstm':
            # Retrain LSTM on full dataset
            feature_cols = [col for col in latest_data.columns if col not in ['date', 'WS_Spot_next_day']]
            X = self.scaler.fit_transform(latest_data[feature_cols])
            
            # Get latest window
            X_window = X[-self.window_size:]
            X_tensor = torch.FloatTensor(X_window).unsqueeze(0)
            
            # Monte Carlo predictions
            predictions = []
            self.lstm_model.train()
            for _ in range(self.n_iterations):
                with torch.no_grad():
                    pred = self.lstm_model(X_tensor).item()
                    predictions.append(pred)
            
            next_day = latest_data.iloc[-1]['date'] + pd.Timedelta(days=1)
            return {
                'Date': next_day,
                'Predicted': np.mean(predictions),
                'Lower_Bound': np.percentile(predictions, 10),
                'Upper_Bound': np.percentile(predictions, 90),
                'Direction': np.sign(np.mean(predictions) - latest_data.iloc[-1]['WS_Spot'])
            }
        
        else:  # ARIMA
            pred, conf_int = self.arima_model.predict(n_periods=1, return_conf_int=True)
            next_day = latest_data.iloc[-1]['date'] + pd.Timedelta(days=1)
            return {
                'Date': next_day,
                'Predicted': pred[0],
                'Lower_Bound': conf_int[0][0],
                'Upper_Bound': conf_int[0][1],
                'Direction': np.sign(pred[0] - latest_data.iloc[-1]['WS_Spot'])
            }
    
    def scenario_analysis(self, df, export_increase, model_type='lstm'):
        """Perform scenario analysis with modified export values"""
        # Modify export data
        scenario_df = df.copy()
        scenario_df['Exp_TD3C_KBD'] += export_increase
        
        # Get prediction with modified data
        return self.predict_next_day(scenario_df, model_type)

# Usage example
def main():
    # Load your data
    df = pd.read_csv('td3c_data.csv', parse_dates=['date'])
    
    # Initialize pipeline
    pipeline = TD3CPredictionPipeline()
    
    # Train and evaluate models
    lstm_results, arima_results = pipeline.train_evaluate_models(df)
    
    # Print results
    for model_name, results in [('LSTM', lstm_results), ('ARIMA', arima_results)]:
        print(f"\n{model_name} Results:")
        print(f"Train MAE: {results['train_mae']:.2f}")
        print(f"Validation MAE: {results['val_mae']:.2f}")
        print("\nTest Results:")
        print(results['test_results'].head())
    
    # Get user input for model selection
    model_choice = input("Choose model for prediction (lstm/arima): ").lower()
    
    # Predict next day
    next_day_pred = pipeline.predict_next_day(df, model_choice)
    print("\nNext Day Prediction:")
    print(next_day_pred)
    
    # Scenario analysis
    export_increase = float(input("Enter export increase in KBD: "))
    scenario_pred = pipeline.scenario_analysis(df, export_increase, model_choice)
    print("\nScenario Analysis Prediction:")
    print(scenario_pred)

if __name__ == "__main__":
    main()
