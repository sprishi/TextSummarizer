from keras.utils import to_categorical

# Encoding target variables for Neural Network
le_load = LabelEncoder()
y_train_load_encoded = le_load.fit_transform(y_train_load)
y_train_load_onehot = to_categorical(y_train_load_encoded)

le_discharge = LabelEncoder()
y_train_discharge_encoded = le_discharge.fit_transform(y_train_discharge)
y_train_discharge_onehot = to_categorical(y_train_discharge_encoded)



from keras.models import Sequential
from keras.layers import LSTM, Dense

# Define LSTM architecture for loadcountry
model_load = Sequential()
model_load.add(LSTM(50, input_shape=(X_train.shape[1], 1))) # 50 LSTM units
model_load.add(Dense(y_train_load_onehot.shape[1], activation='softmax'))
model_load.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Define LSTM architecture for dischargecountry
model_discharge = Sequential()
model_discharge.add(LSTM(50, input_shape=(X_train.shape[1], 1))) # 50 LSTM units
model_discharge.add(Dense(y_train_discharge_onehot.shape[1], activation='softmax'))
model_discharge.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])




# Reshape input data for LSTM [samples, timesteps, features]
X_train_reshaped = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))

# Train model for loadcountry
model_load.fit(X_train_reshaped, y_train_load_onehot, epochs=10, batch_size=32)

# Train model for dischargecountry
model_discharge.fit(X_train_reshaped, y_train_discharge_onehot, epochs=10, batch_size=32)





# Reshape test data
X_test_reshaped = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))

# Predictions
y_pred_load_probs = model_load.predict(X_test_reshaped)
y_pred_discharge_probs = model_discharge.predict(X_test_reshaped)

# Get class labels
y_pred_load = le_load.inverse_transform(y_pred_load_probs.argmax(axis=1))
y_pred_discharge = le_discharge.inverse_transform(y_pred_discharge_probs.argmax(axis=1))

# ... Remaining steps for evaluation and extracting top 3 predictions remain similar ...
