import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.api import VAR
import matplotlib.pyplot as plt

# Assume your data is already loaded into a DataFrame 'data'
ratio_data = data[['Aframax', 'Suezmax', 'VLCC']]

# Function to perform ADF test
def adf_test(series, name=''):
    result = adfuller(series, autolag='AIC')
    print(f'ADF Statistic for {name}: {result[0]}')
    print(f'p-value for {name}: {result[1]}')
    print('Critical Values:')
    for key, value in result[4].items():
        print(f'   {key}, {value}')
    return result[1]  # Return p-value

# Check stationarity for each column
p_values = {}
for column in ratio_data.columns:
    p_value = adf_test(ratio_data[column].dropna(), name=column)  # .dropna() to handle initial NaNs if any
    p_values[column] = p_value

# Check if differencing is needed
differenced_data = ratio_data.copy()
differencing_applied = {}
for column, p_value in p_values.items():
    if p_value > 0.05:  # Non-stationary series
        differenced_data[column] = ratio_data[column].diff().dropna()
        differencing_applied[column] = True
    else:
        differencing_applied[column] = False

# Re-test stationarity after differencing
differenced_p_values = {}
for column in differenced_data.columns:
    p_value = adf_test(differenced_data[column].dropna(), name=f'Differenced {column}')
    differenced_p_values[column] = p_value

# Check if second differencing is needed
second_differenced_data = differenced_data.copy()
second_differencing_applied = {}
for column, p_value in differenced_p_values.items():
    if p_value > 0.05:  # Still non-stationary series after first differencing
        second_differenced_data[column] = differenced_data[column].diff().dropna()
        second_differencing_applied[column] = True
    else:
        second_differencing_applied[column] = False

# Ensure second_differenced_data is correctly aligned after second differencing
second_differenced_data = second_differenced_data.dropna()

# Fit the VAR model with stationary data up to June 2024
model = VAR(second_differenced_data)
results = model.select_order(maxlags=15)
selected_order = results.aic
print(f"Selected order: {selected_order}")

model_fitted = model.fit(selected_order)
print(model_fitted.summary())

# Forecasting the future values for the next 18 months
forecast_steps = 18
forecast = model_fitted.forecast(second_differenced_data.values[-selected_order:], steps=forecast_steps)

# Convert forecast to DataFrame
forecast_dates = pd.date_range(start=second_differenced_data.index[-1] + pd.offsets.MonthBegin(), periods=forecast_steps, freq='MS')
forecast_df = pd.DataFrame(forecast, index=forecast_dates, columns=ratio_data.columns)

# Reverse differencing if applied
for column in forecast_df.columns:
    if second_differencing_applied[column]:
        forecast_df[column] = differenced_data[column].iloc[-1] + forecast_df[column].cumsum()
    elif differencing_applied[column]:
        forecast_df[column] = ratio_data[column].iloc[-1] + forecast_df[column].cumsum()

# Concatenate the actual and forecasted data for visualization
combined_df = pd.concat([ratio_data, forecast_df], axis=0)

# Plot the forecasted ratios
plt.figure(figsize=(14, 7))
for column in combined_df.columns:
    plt.plot(combined_df.index, combined_df[column], label=f'{column} (Forecast)')
    plt.plot(ratio_data.index, ratio_data[column], label=f'{column} (Actual)', linestyle='--')

plt.title('Forecasted vs Actual Vessel Class Ratios')
plt.xlabel('Date')
plt.ylabel('Ratios')
plt.legend()
plt.show()




-------

import pandas as pd
from geopy.distance import geodesic
from datetime import timedelta
from scipy.spatial import cKDTree
import numpy as np

# Sample AIS data with draught and destination
data = {
    'timestamp': [
        '2024-05-01 00:00:00', '2024-05-02 01:00:00', '2024-05-03 02:00:00', 
        '2024-05-04 00:05:00', '2024-05-05 01:05:00', '2024-05-06 02:05:00',
        '2024-05-07 03:05:00', '2024-05-08 04:05:00', '2024-05-09 05:05:00',
        '2024-05-10 06:05:00', '2024-05-11 07:05:00', '2024-05-12 08:05:00'
    ],
    'MMSI': [123456789, 123456789, 123456789, 987654321, 987654321, 987654321, 
             123456789, 123456789, 123456789, 987654321, 987654321, 987654321],
    'latitude': [25.0, 25.1, 25.2, 25.0, 25.1, 25.2, 25.3, 25.4, 25.5, 25.6, 25.7, 25.8],
    'longitude': [55.0, 55.1, 55.2, 55.0, 55.1, 55.2, 55.3, 55.4, 55.5, 55.6, 55.7, 55.8],
    'speed': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],
    'heading': [90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90],
    'draught': [5.0, 5.2, 5.4, 10.0, 9.8, 9.6, 5.5, 5.6, 5.7, 9.5, 9.4, 9.3],  # Sample draught values
    'destination': ['Port A', 'Port A', 'Port A', 'Port B', 'Port B', 'Port B', 
                    'Port C', 'Port C', 'Port C', 'Port D', 'Port D', 'Port D']  # Sample destination values
}

# List of port coordinates (latitude, longitude)
ports = [(25.0, 55.0), (24.5, 54.5)]  # Example port coordinates

# Load data into a DataFrame
df = pd.DataFrame(data)

# Convert timestamp to datetime
df['timestamp'] = pd.to_datetime(df['timestamp'])

# Group data by ship (MMSI)
grouped = df.groupby('MMSI')

# Define a function to calculate distance between two points
def calculate_distance(lat1, lon1, lat2, lon2):
    return geodesic((lat1, lon1), (lat2, lon2)).meters

# Define a function to check if a ship is near any port
def is_near_port(lat, lon, ports, max_distance=1000):
    for port in ports:
        if calculate_distance(lat, lon, port[0], port[1]) < max_distance:
            return True
    return False

# Create KD-Tree for spatial indexing
coords = df[['latitude', 'longitude']].to_numpy()
tree = cKDTree(coords)

# Identify potential STS operations
sts_operations = []

# Iterate over ship pairs and find potential STS operations
for ship1, data1 in grouped:
    data1 = data1.sort_values(by='timestamp')
    indices1 = data1.index

    for ship2, data2 in grouped:
        if ship1 >= ship2:  # Avoid duplicate checks and self-comparison
            continue

        data2 = data2.sort_values(by='timestamp')
        indices2 = data2.index

        # Use KD-Tree to find nearby points
        close_pairs = tree.query_ball_point(data1[['latitude', 'longitude']].to_numpy(), r=0.5)  # 500 meters

        for i, close_indices in enumerate(close_pairs):
            if len(close_indices) == 0:
                continue

            # Filter indices for ship2
            close_indices = [idx for idx in close_indices if idx in indices2]
            if len(close_indices) == 0:
                continue

            row1 = data1.iloc[i]
            window_data2 = data2.loc[close_indices]

            close_ships = window_data2[
                (abs(window_data2['speed'] - row1['speed']) < 1) &
                (abs(window_data2['heading'] - row1['heading']) < 10) &
                (window_data2['speed'] < 6) &
                (~window_data2.apply(lambda row: is_near_port(row['latitude'], row['longitude'], ports), axis=1)) &
                (~is_near_port(row1['latitude'], row1['longitude'], ports))
            ]

            if not close_ships.empty:
                start_time = row1['timestamp']
                end_time = close_ships['timestamp'].max()
                total_nearby_time = end_time - start_time

                start_draught_ship1 = row1['draught']
                end_draught_ship1 = row1['draught']
                start_draught_ship2 = close_ships['draught'].iloc[0]
                end_draught_ship2 = close_ships['draught'].iloc[-1]

                draught_change_ship1 = ((end_draught_ship1 - start_draught_ship1) / start_draught_ship1 * 100)
                draught_change_ship2 = ((end_draught_ship2 - start_draught_ship2) / start_draught_ship2 * 100)

                sts_operations.append({
                    'ship1': ship1,
                    'ship2': ship2,
                    'start_time': start_time,
                    'end_time': end_time,
                    'total_nearby_time': total_nearby_time,
                    'draught_change_ship1 (%)': draught_change_ship1,
                    'draught_change_ship2 (%)': draught_change_ship2,
                    'destination_ship1': row1['destination'],
                    'destination_ship2': close_ships['destination'].iloc[0]
                })

# Convert STS operations to a DataFrame for better readability
sts_df = pd.DataFrame(sts_operations)

# Example of accessing the chain for a specific mothership
for index, row in sts_df.iterrows():
    print(f"Ship1 {row['ship1']} and Ship2 {row['ship2']} performed STS operations from {row['start_time']} to {row['end_time']}.")




============

import pandas as pd
from geopy.distance import geodesic
from datetime import datetime, timedelta

# Sample AIS data with draught and destination
data = {
    'timestamp': [
        '2024-05-01 00:00:00', '2024-05-02 01:00:00', '2024-05-03 02:00:00', 
        '2024-05-04 00:05:00', '2024-05-05 01:05:00', '2024-05-06 02:05:00',
        '2024-05-07 03:05:00', '2024-05-08 04:05:00', '2024-05-09 05:05:00',
        '2024-05-10 06:05:00', '2024-05-11 07:05:00', '2024-05-12 08:05:00'
    ],
    'MMSI': [123456789, 123456789, 123456789, 987654321, 987654321, 987654321, 
             123456789, 123456789, 123456789, 987654321, 987654321, 987654321],
    'latitude': [25.0, 25.1, 25.2, 25.0, 25.1, 25.2, 25.3, 25.4, 25.5, 25.6, 25.7, 25.8],
    'longitude': [55.0, 55.1, 55.2, 55.0, 55.1, 55.2, 55.3, 55.4, 55.5, 55.6, 55.7, 55.8],
    'speed': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],
    'heading': [90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90],
    'draught': [5.0, 5.2, 5.4, 10.0, 9.8, 9.6, 5.5, 5.6, 5.7, 9.5, 9.4, 9.3],  # Sample draught values
    'destination': ['Port A', 'Port A', 'Port A', 'Port B', 'Port B', 'Port B', 
                    'Port C', 'Port C', 'Port C', 'Port D', 'Port D', 'Port D']  # Sample destination values
}

# List of port coordinates (latitude, longitude)
ports = [(25.0, 55.0), (24.5, 54.5)]  # Example port coordinates

# Load data into a DataFrame
df = pd.DataFrame(data)

# Convert timestamp to datetime
df['timestamp'] = pd.to_datetime(df['timestamp'])

# Group data by ship (MMSI)
grouped = df.groupby('MMSI')

# Define a function to calculate distance between two points
def calculate_distance(lat1, lon1, lat2, lon2):
    return geodesic((lat1, lon1), (lat2, lon2)).meters

# Define a function to check if a ship is near any port
def is_near_port(lat, lon, ports, max_distance=1000):
    for port in ports:
        if calculate_distance(lat, lon, port[0], port[1]) < max_distance:
            return True
    return False

# Identify potential STS operations
sts_operations = []
chains = []

# Create a dictionary to store data for quick lookup
data_dict = {mmsi: group for mmsi, group in grouped}

for ship1, data1 in data_dict.items():
    for ship2, data2 in data_dict.items():
        if ship1 >= ship2:  # Avoid duplicate checks and self-comparison
            continue

        data1 = data1.sort_values(by='timestamp')
        data2 = data2.sort_values(by='timestamp')
        consecutive_nearby_time = timedelta(0)
        total_nearby_time = timedelta(0)
        start_time = None
        end_time = None
        start_draught_ship1 = None
        end_draught_ship1 = None
        start_draught_ship2 = None
        end_draught_ship2 = None

        # Iterate over data1 and use vectorized operations for data2 within the 5-minute window
        for _, row1 in data1.iterrows():
            time_window = (row1['timestamp'] - timedelta(minutes=5), row1['timestamp'] + timedelta(minutes=5))
            window_data2 = data2[(data2['timestamp'] >= time_window[0]) & (data2['timestamp'] <= time_window[1])]

            if not window_data2.empty:
                distances = window_data2.apply(lambda row: calculate_distance(row1['latitude'], row1['longitude'], row['latitude'], row['longitude']), axis=1)
                close_ships = window_data2[(distances < 500) & (abs(window_data2['speed'] - row1['speed']) < 1) & (abs(window_data2['heading'] - row1['heading']) < 10) & (window_data2['speed'] < 6)]

                if not close_ships.empty and not is_near_port(row1['latitude'], row1['longitude'], ports) and not is_near_port(close_ships.iloc[0]['latitude'], close_ships.iloc[0]['longitude'], ports):
                    if start_time is None:
                        start_time = row1['timestamp']
                    end_time = row1['timestamp']
                    if last_nearby_time:
                        consecutive_nearby_time = row1['timestamp'] - last_nearby_time
                    last_nearby_time = row1['timestamp']
                    total_nearby_time += consecutive_nearby_time
                    if start_draught_ship1 is None:
                        start_draught_ship1 = row1['draught']
                    end_draught_ship1 = row1['draught']
                    if start_draught_ship2 is None:
                        start_draught_ship2 = close_ships.iloc[0]['draught']
                    end_draught_ship2 = close_ships.iloc[0]['draught']
                else:
                    consecutive_nearby_time = timedelta(0)
                    last_nearby_time = None

        latest_timestamp_ship1 = data1['timestamp'].max()
        latest_timestamp_ship2 = data2['timestamp'].max()
        still_nearby = last_nearby_time == latest_timestamp_ship1 or last_nearby_time == latest_timestamp_ship2

        if total_nearby_time > timedelta(hours=4) or still_nearby:
            # Calculate draught percentage change
            draught_change_ship1 = ((end_draught_ship1 - start_draught_ship1) / start_draught_ship1 * 100) if start_draught_ship1 else None
            draught_change_ship2 = ((end_draught_ship2 - start_draught_ship2) / start_draught_ship2 * 100) if start_draught_ship2 else None
            sts_operations.append({
                'ship1': ship1,
                'ship2': ship2,
                'start_time': start_time,
                'end_time': end_time,
                'total_nearby_time': total_nearby_time,
                'last_nearby_time': last_nearby_time,
                'current_status': 'performing STS' if still_nearby else 'not performing STS',
                'draught_change_ship1 (%)': draught_change_ship1,
                'draught_change_ship2 (%)': draught_change_ship2,
                'destination_ship1': data1['destination'].iloc[-1],
                'destination_ship2': data2['destination'].iloc[-1]
            })

# Identify chains of STS operations
# Convert STS operations to a DataFrame for better readability
sts_df = pd.DataFrame(sts_operations)

# Track chains of STS operations with identifiers
motherships = {}
group_id = 1

for _, row in sts_df.iterrows():
    ship1 = row['ship1']
    ship2 = row['ship2']
    
    # Initialize entries if not present
    if ship1 not in motherships and ship2 not in motherships:
        # Both ships are new, create a new group
        motherships[ship1] = {'childships': set(), 'operations': [], 'group_id': group_id}
        motherships[ship2] = {'childships': set(), 'operations': [], 'group_id': group_id}
        group_id += 1
    elif ship1 in motherships and ship2 not in motherships:
        # Ship1 exists, add ship2 to ship1's group
        motherships[ship2] = {'childships': set(), 'operations': [], 'group_id': motherships[ship1]['group_id']}
    elif ship2 in motherships and ship1 not in motherships:
        # Ship2 exists, add ship1 to ship2's group
        motherships[ship1] = {'childships': set(), 'operations': [], 'group_id': motherships[ship2]['group_id']}
    
    # Add ship2 as a childship of ship1 and record the operation
    motherships[ship1]['childships'].add(ship2)
    motherships[ship1]['operations'].append(row)
    
    # Add ship1 as a childship of ship2 and record the operation
    motherships[ship2]['childships'].add(ship1)
    motherships[ship2]['operations'].append(row)
    
    # Ensure both ships have the same group_id
    motherships[ship2]['group_id'] = motherships[ship1]['group_id']

# Add group_id to the final dataframe
sts_df['group_id'] = sts_df.apply(lambda row: motherships[row['ship1']]['group_id'], axis=1)

# Sort the dataframe by recency
sts_df = sts_df.sort_values(by='end_time', ascending=False)

# Example of accessing the chain for a specific group
for group_id, details in sorted(motherships.items(), key=lambda x: x[1]['group_id']):
    print(f"Group {group_id} has performed STS operations with ships {details['childships']}")
    print("STS operations:")
    print(pd.DataFrame(details['operations']))

print(sts_df)

====================

import pandas as pd
from geopy.distance import geodesic
from datetime import datetime, timedelta

# Sample AIS data with draught and destination
data = {
    'timestamp': [
        '2024-05-23 00:00:00', '2024-05-23 01:00:00', '2024-05-23 02:00:00', 
        '2024-05-23 00:05:00', '2024-05-23 01:05:00', '2024-05-23 02:05:00'
    ],
    'MMSI': [123456789, 123456789, 123456789, 987654321, 987654321, 987654321],
    'latitude': [25.0, 25.1, 25.2, 25.0, 25.1, 25.2],
    'longitude': [55.0, 55.1, 55.2, 55.0, 55.1, 55.2],
    'speed': [3, 3, 3, 3, 3, 3],
    'heading': [90, 90, 90, 90, 90, 90],
    'draught': [5.0, 5.2, 5.4, 10.0, 9.8, 9.6],  # Sample draught values
    'destination': ['Port A', 'Port A', 'Port A', 'Port B', 'Port B', 'Port B']  # Sample destination values
}

# List of port coordinates (latitude, longitude)
ports = [(25.0, 55.0), (24.5, 54.5)]  # Example port coordinates

# Load data into a DataFrame
df = pd.DataFrame(data)

# Convert timestamp to datetime
df['timestamp'] = pd.to_datetime(df['timestamp'])

# Group data by ship (MMSI)
grouped = df.groupby('MMSI')

# Define a function to calculate distance between two points
def calculate_distance(lat1, lon1, lat2, lon2):
    return geodesic((lat1, lon1), (lat2, lon2)).meters

# Define a function to check if a ship is near any port
def is_near_port(lat, lon, ports, max_distance=1000):
    for port in ports:
        if calculate_distance(lat, lon, port[0], port[1]) < max_distance:
            return True
    return False

# Identify potential STS operations
sts_operations = []

# Create a dictionary to store data for quick lookup
data_dict = {mmsi: group for mmsi, group in grouped}

for ship1, data1 in data_dict.items():
    for ship2, data2 in data_dict.items():
        if ship1 >= ship2:  # Avoid duplicate checks and self-comparison
            continue

        data1 = data1.sort_values(by='timestamp')
        data2 = data2.sort_values(by='timestamp')
        consecutive_nearby_time = timedelta(0)
        total_nearby_time = timedelta(0)
        start_time = None
        end_time = None
        start_draught_ship1 = None
        end_draught_ship1 = None
        start_draught_ship2 = None
        end_draught_ship2 = None

        # Iterate over data1 and use vectorized operations for data2 within the 5-minute window
        for _, row1 in data1.iterrows():
            time_window = (row1['timestamp'] - timedelta(minutes=5), row1['timestamp'] + timedelta(minutes=5))
            window_data2 = data2[(data2['timestamp'] >= time_window[0]) & (data2['timestamp'] <= time_window[1])]

            if not window_data2.empty:
                distances = window_data2.apply(lambda row: calculate_distance(row1['latitude'], row1['longitude'], row['latitude'], row['longitude']), axis=1)
                close_ships = window_data2[(distances < 500) & (abs(window_data2['speed'] - row1['speed']) < 1) & (abs(window_data2['heading'] - row1['heading']) < 10) & (window_data2['speed'] < 6)]

                if not close_ships.empty and not is_near_port(row1['latitude'], row1['longitude'], ports) and not is_near_port(close_ships.iloc[0]['latitude'], close_ships.iloc[0]['longitude'], ports):
                    if start_time is None:
                        start_time = row1['timestamp']
                    end_time = row1['timestamp']
                    if last_nearby_time:
                        consecutive_nearby_time = row1['timestamp'] - last_nearby_time
                    last_nearby_time = row1['timestamp']
                    total_nearby_time += consecutive_nearby_time
                    if start_draught_ship1 is None:
                        start_draught_ship1 = row1['draught']
                    end_draught_ship1 = row1['draught']
                    if start_draught_ship2 is None:
                        start_draught_ship2 = close_ships.iloc[0]['draught']
                    end_draught_ship2 = close_ships.iloc[0]['draught']
                else:
                    consecutive_nearby_time = timedelta(0)
                    last_nearby_time = None

        latest_timestamp_ship1 = data1['timestamp'].max()
        latest_timestamp_ship2 = data2['timestamp'].max()
        latest_timestamp = max(latest_timestamp_ship1, latest_timestamp_ship2)
        still_nearby = last_nearby_time == latest_timestamp

        if total_nearby_time > timedelta(hours=4) or still_nearby:
            # Calculate draught percentage change
            draught_change_ship1 = ((end_draught_ship1 - start_draught_ship1) / start_draught_ship1 * 100) if start_draught_ship1 else None
            draught_change_ship2 = ((end_draught_ship2 - start_draught_ship2) / start_draught_ship2 * 100) if start_draught_ship2 else None
            sts_operations.append({
                'ship1': ship1,
                'ship2': ship2,
                'start_time': start_time,
                'end_time': end_time,
                'total_nearby_time': total_nearby_time,
                'last_nearby_time': last_nearby_time,
                'current_status': 'performing STS' if still_nearby else 'not performing STS',
                'draught_change_ship1 (%)': draught_change_ship1,
                'draught_change_ship2 (%)': draught_change_ship2,
                'destination_ship1': data1['destination'].iloc[-1],
                'destination_ship2': data2['destination'].iloc[-1]
            })

# Convert STS operations to a DataFrame for better readability
sts_df = pd.DataFrame(sts_operations)
print(sts_df)
